{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HSI-train.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"18Q0Ij03ypqVxzL7M6zDLPDtpGSjU0qyL","authorship_tag":"ABX9TyP4GMWaHE6e+eWI/rf5zBh4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0u5e3xM0kNhT"},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KvX8C_LDkdR8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rIa2j9i6kq9D"},"source":["#%reset\n","import numpy as np\n","import argparse\n","import re\n","import os, glob, datetime\n","#tensorflow==2.1.0\n","#tensorflow-estimator==2.1.0\n","import tensorflow as tf\n","import numpy as np\n","from keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract\n","from keras.models import Model, load_model\n","from keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n","from keras.optimizers import Adam\n","#import data_generator as dg\n","import keras.backend as K\n","import sys\n","sys.path.insert(0, \"/modules\")\n","sys.path.append('/utils')\n","print(sys.path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"duOlbSRFkxL3"},"source":["# Model configuration\n","patch_size=40\n","#img_width, img_height = patch_size, patch_size\n","img_width, img_height = 181, 217\n","bands=6\n","#batch_size = 150\n","batch_size = 25\n","print(\"hey there!\")\n","no_epochs = 50\n","validation_split = 0.2\n","verbosity = 1\n","max_norm_value = 2.0\n","noise_factor = 0.55\n","number_of_visualizations = 6"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xVlVPvOtC4mR"},"source":["import numpy as np\n","from hsi_preprocess import *\n","from keras.models import load_model\n","# Load 3D data from CAVE datasets (numbered 1 to 25)\n","i=1\n","img3d=np.load('/data/HSI/CAVE/CAVE3d_'+format(i,\"0>2d\")+'.npy')\n","a=mri_3d_extract(img3d,patch_size=40,channels=1) # to extract 2d data (no. of channels=1)\n","#a=mri_3d_extract(img3d,patch_size=40,channels=6) # to extract 3d data (no. of channels=more)\n","for i in range(1,5):\n","  img3d=np.load('/data/HSI/CAVE/CAVE3d_'+format(i+1,\"0>2d\")+'.npy')\n","  patches=mri_3d_extract(img3d,patch_size=40,channels=1) # to extract 2d data (no. of channels=1)\n","  #patches=mri_3d_extract(img3d,patch_size=40,channels=6) # to extract 3d data (no. of channels=more)\n","  a=np.concatenate([a,patches])\n","print(a.shape)\n","##############################################################################################\n","\n","#a=np.load('/content/drive/My Drive/VAE/data/HSI/CAVE/balloons_ms/balloons3DPatches.npy')\n","\n","img_width,img_height,layers=patch_size,patch_size,bands\n","#Reshaping data  \n","if K.image_data_format() == 'channels_first':\n","    print(\"channel first format\")\n","    # Considering 3D data\n","    #input_train = a.reshape(a.shape[0], 1, img_width, img_height,layers)\n","    #input_shape = (1, img_width, img_height,layers)\n","    \n","    # Considering 2D data\n","    input_train = a.reshape(a.shape[0], 1, img_width, img_height)\n","    input_shape = (1, img_width, img_height)\n","else:\n","    print(\"channel last format\")\n","    \n","    # Considering 3D data\n","    #input_train = a.reshape(a.shape[0], img_width, img_height,layers,1)\n","    #input_shape = (img_width, img_height, layers, 1)\n","    \n","    #Considering 2D data\n","    input_train = a.reshape(a.shape[0], img_width, img_height,1)\n","    input_shape = (img_width, img_height, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hkvBM_JaNFOr"},"source":["#################### Normalize Input Data ##########################\n","\n","print(a.shape)\n","print(input_train[0].shape)\n","numOfSamples= input_train.shape[0]\n","for i in range(numOfSamples):\n","    # Normalise data between [0,1] (for each sample)\n","    input_train[i] = (input_train[i] - np.min(input_train[i]))/np.ptp(input_train[i])\n","    # Normalise data between[0,255] (per sample) as integer: don't forget the parenthesis before astype(int)\n","    #input_train[i] = (255*(input_train[i] - np.min(input_train[i]))/np.ptp(input_train[i])).astype(int)        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eWSgAlKUaS25"},"source":["print(input_train[0].shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UcJHKL3aG9hG"},"source":["# Add noise\n","from numpy.random import seed\n","from numpy.random import randint\n","from mri_preprocess import *\n","\n","#print(randint(1,5,1))\n","\n","pure_train = input_train\n","\n","# for 2D data\n","noisy_input_train=add_gaussian_noise(input_train,10)\n","noisy_input_train=add_impulse_noise(noisy_input_train,20)\n","\n","# for 3d data\n","#noisy_input_train=add_gaussian_noise3D(input_train,10)\n","#noisy_input_train=add_impulse_noise3D(noisy_input_train,20)\n","#noisy_input_test=noisy_input_test.astype('float32')\n","print(noisy_input_train.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4yGUn9diYmTn"},"source":["#################### Normalize Noisy Data ##########################\n","\n","print(a.shape)\n","print(input_train[0].shape)\n","numOfSamples= input_train.shape[0]\n","for i in range(numOfSamples):\n","    # Normalise data between [0,1] (for each sample)\n","    noisy_input_train[i] = (noisy_input_train[i] - np.min(noisy_input_train[i]))/np.ptp(noisy_input_train[i])\n","    # Normalise data between[0,255] (per sample) as integer: don't forget the parenthesis before astype(int)\n","    #input_train[i] = (255*(input_train[i] - np.min(input_train[i]))/np.ptp(input_train[i])).astype(int)  \n","\n","#print(input_train[0].shape)      "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WJXSYmj3pGWE"},"source":["# -*- coding: utf-8 -*-\n","\n","import numpy as np\n","#import tensorflow as tf\n","from keras.models import *\n","from keras.layers import  Input,Conv2D,Conv3D,BatchNormalization,Activation,Lambda,Subtract,concatenate,Add,merge\n","\n","import keras.backend  as K\n","#from group_norm import GroupNormalization #\n","#from batch_renorm import BatchRenormalization\n","#def BRDNet(): #original format def BRDNet(), data is used to obtain the reshape of input data\n","#inpt = Input(shape=(None,None,None, 1)) #if the image is 3, it is color image. If the image is 1, it is gray color, 201807082123tcw\n","inpt = Input(shape=(None,None, 1)) #if the image is 3, it is color image. If the image is 1, it is gray color, 201807082123tcw\n","# 1st layer, Conv+relu\n","#x = Conv3D(filters=128, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(inpt)\n","x = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same')(inpt)\n","#x = BatchRenormalization(axis=-1, epsilon=1e-3)(x)\n","x = BatchNormalization(axis=-1, epsilon=1e-3,renorm=1)(x)\n","x = Activation('relu')(x)\n","# 15 layers, Conv+BN+relu\n","for i in range(7):\n","    #x = Conv3D(filters=128, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(x)\n","    x = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same')(x)\n","    #x = BatchRenormalization(axis=-1, epsilon=1e-3)(x)\n","    x = BatchNormalization(axis=-1, epsilon=1e-3,renorm=1)(x)\n","    x = Activation('relu')(x)   \n","# last layer, Conv \n","for i in range(8):\n","    #x = Conv3D(filters=128, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(x)\n","    x = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same')(x)\n","    #x = BatchRenormalization(axis=-1, epsilon=1e-3)(x)\n","    x = BatchNormalization(axis=-1, epsilon=1e-3,renorm=1)(x)\n","    x = Activation('relu')(x) \n","#x = Conv3D(filters=1, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(x) #gray is 1 color is 3\n","x = Conv2D(filters=1, kernel_size=(3,3), strides=(1,1), padding='same')(x) #gray is 1 color is 3\n","x = Subtract()([inpt, x])   # input - noise\n","#y = Conv3D(filters=128, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(inpt)\n","y = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same')(inpt)\n","#y = BatchRenormalization(axis=-1, epsilon=1e-3)(y)\n","y = BatchNormalization(axis=-1, epsilon=1e-3,renorm=1)(y)\n","y = Activation('relu')(y)\n","# 15 layers, Conv+BN+relu\n","for i in range(7):\n","    #y = Conv3D(filters=128, kernel_size=(3,3,3), strides=(1,1,1),dilation_rate=(2,2,2), padding='same')(y)\n","    y = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1),dilation_rate=(2,2), padding='same')(y)\n","    y = Activation('relu')(y)   \n","#y = Conv3D(filters=128, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(y)\n","y = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same')(y)\n","#y = BatchRenormalization(axis=-1, epsilon=1e-3)(y)\n","y = BatchNormalization(axis=-1, epsilon=1e-3,renorm=1)(y)\n","y = Activation('relu')(y) \n","for i in range(6):\n","    #y = Conv3D(filters=64, kernel_size=(3,3,3), strides=(1,1,1),dilation_rate=(2,2,2), padding='same')(y)\n","    y = Conv2D(filters=128, kernel_size=(3,3), strides=(1,1),dilation_rate=(2,2), padding='same')(y)\n","    y = Activation('relu')(y)\n","#y = Conv3D(filters=128, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(y)\n","y = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same')(y)\n","#y = BatchRenormalization(axis=-1, epsilon=1e-3)(y)\n","y = BatchNormalization(axis=-1, epsilon=1e-3,renorm=1)(y)\n","y = Activation('relu')(y)    \n","#y = Conv3D(filters=1, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(y)#gray is 1 color is 3\n","y = Conv2D(filters=1, kernel_size=(3,3), strides=(1,1), padding='same')(y)#gray is 1 color is 3\n","y = Subtract()([inpt, y])   # input - noise\n","o = concatenate([x,y],axis=-1)\n","#z = Conv3D(filters=1, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(o)#gray is 1 color is 3\n","z = Conv2D(filters=1, kernel_size=(3,3), strides=(1,1), padding='same')(o)#gray is 1 color is 3\n","z=  Subtract()([inpt, z])\n","model = Model(inputs=inpt, outputs=z)\n","#model.summary()\n","#return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Uqhx69ygPlU"},"source":["#from losses import ssim_loss\n","#from mymetrics import ssim_metric,psnr_metric,ssim_loss\n","from keras.losses import mean_squared_error, mean_absolute_error\n","from skimage.metrics import structural_similarity as ssim\n","import skimage.metrics\n","import pytorch_ssim\n","import torch\n","from torch.autograd import Variable\n","from skimage import measure\n","import math\n","def ssim_metric2d(y_true, y_pred):\n","  return tf.reduce_mean(tf.image.ssim(y_true, y_pred, 2.0))\n","\n","def ssim_metric3d(y_true, y_pred):\n","  return tf.reduce_mean(tf.image.ssim(y_true, y_pred, 2.0,filter_size=5))\n","\n","def psnr_metric(y_true, y_pred):\n","    \"\"\"\n","    PSNR is Peek Signal to Noise Ratio, which is similar to mean squared error.\n","    It can be calculated as\n","    PSNR = 20 * log10(MAXp) - 10 * log10(MSE)\n","    When providing an unscaled input, MAXp = 255. Therefore 20 * log10(255)== 48.1308036087.\n","    However, since we are scaling our input, MAXp = 1. Therefore 20 * log10(1) = 0.\n","    Thus we remove that component completely and only compute the remaining MSE component.\n","    \"\"\"\n","    return -10. * K.log(K.mean(K.square(y_pred - y_true)))\n","def psnr_met1(y_true, y_pred):\n","    max_pixel = 1.0\n","    return (10.0 * K.log((max_pixel ** 2) / (K.mean(K.square(y_pred - y_true), axis=-1)))) / 2.303\n","\n","# Loss functtion\n","def ssim_loss1(y_true, y_pred):\n","    myssim=tf.image.ssim(y_true, y_pred,1)\n","    s_3d_tf = tf.Session().run(myssim)\n","    return tf.reduce_mean((1.0-s_3d_tf)/2.0)\n","\n","def ssim_loss2(y_true, y_pred):\n","    print(y_true.dtype)\n","    img1=torch.cuda.FloatTensor(y_true)\n","    img2=torch.cuda.FloatTensor(y_pred)\n","    #img1=tf.convert_to_tensor(y_true)\n","    #img2=tf.convert_to_tensor(y_pred)\n","    print(img1.dtype)\n","    print(img2.shape)\n","    ssim_3d_sk=pytorch_ssim.ssim3D(y_true, y_pred)\n","    #ssim_3d_sk = skimage.metrics.structural_similarity(y_true, y_pred, multichannel=False, gaussian_weights=True, data_range=1.0, use_sample_covariance=False)\n","    #ssim_3d_sk = ssim(img1, img2,win_size=3, gaussian_weights=True, data_range=1.0, use_sample_covariance=False)\n","    return tf.reduce_mean((1.0-ssim_3d_sk)/2.0)\n","\n","# Loss functtion\n","def ssim_loss2d(y_true, y_pred):\n","    return tf.reduce_mean((1.0-tf.image.ssim(y_true, y_pred,1))/2.0)\n","\n","def ssim_loss3d(y_true, y_pred):\n","    return tf.reduce_mean((1.0-tf.image.ssim_multiscale(y_true, y_pred,1,filter_size=7))/2.0)\n","\n","def SSIMLoss(y_true, y_pred):\n","  return 1 - tf.reduce_mean(ssim(y_true, y_pred))\n","\n","def psnr_met2(y_true, y_pred):\n","    max_pixel = 1.0\n","    return 10.0 * (1.0 / math.log(10)) * K.log((max_pixel ** 2) / (K.mean(K.square(y_pred - y_true))))\n","\n","def L2_SSIM_loss(y_true, y_pred):\n","  alpha=0.5\n","  return alpha*mean_squared_error(y_true, y_pred) + (1.0-alpha)* ssim_loss(y_true, y_pred) \n","\n","def L1_SSIM_loss(y_true, y_pred):\n","  alpha=0.5\n","  return alpha*mean_absolute_error(y_true, y_pred) + (1.0-alpha)* ssim_loss(y_true, y_pred) \n","\n","def total_content_loss2d(y_true,y_pred):\n","  alpha=0.3\n","  tv_weight=1e-5\n","  '''\n","  Total variation loss is used to keep the image locally coherent\n","   '''\n","  #assert K.ndim(x) == 4\n","  a = tf.square(y_pred[:, :-1, :-1, :] - y_pred[:, 1:, :-1, :])\n","  b = tf.square(y_pred[:, :-1, :-1, :] - y_pred[:, :-1, 1:, :])\n","  #a = tf.square(x[:, : img_nrows - 1, : img_ncols - 1, :] - x[:, 1:, : img_ncols - 1, :])\n","  #b = tf.square(x[:, : img_nrows - 1, : img_ncols - 1, :] - x[:, : img_nrows - 1, 1:, :])\n","  return tv_weight*K.sum(K.pow(a + b,1.25))+alpha*mean_squared_error(y_true,y_pred)+(1-alpha)*mean_absolute_error(y_true,y_pred)\n","\n","def L2_L1_loss(y_true,y_pred):\n","  alpha=0.4\n","  return alpha*mean_squared_error(y_true,y_pred)+(1-alpha)*mean_absolute_error(y_true,y_pred)\n","\n","def mse_TV(y_true,y_pred):\n","  tv_weight=1e-5\n","  mse_weight=0.5\n","  return mse_weight*mean_squared_error(y_true,y_pred)+tv_weight*total_variation_loss(y_pred)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pMXQhNtdm2wp"},"source":["# Compile and fit data\n","from keras.callbacks import CSVLogger\n","from keras import losses\n","from keras import optimizers\n","from mymetrics import *\n","from ganModel import *\n","import keras\n","#from mymetrics import ssim_metric,psnr_met2,ssim_loss\n","csv_logger = CSVLogger('/logs/HSI-logs/logfile-RL2DG10I20_epoch200-L2L1TV-spl-renorm.log', separator=',', append=False)\n","checkpoint = keras.callbacks.ModelCheckpoint('/models/HSI/EnsRL2D-G10I20_{epoch:03d}_L2L1TV-spl-renorm.h5', period=20)\n","adam=optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=True)\n","#sgdm=optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=True)\n","#adam = optimizers.adam(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","#model.compile(loss=losses.mean_square_error, optimizer=adam)\n","#model=generator_model()\n","#residual_train.astype('float32')\n","#print(np.max(residual_train))\n","model.compile(optimizer=adam, loss=total_content_loss2d,metrics=[psnr_met2,ssim_metric2d])\n","model.fit(noisy_input_train, input_train,callbacks=[checkpoint,csv_logger],\n","               epochs=200,\n","             batch_size=30,\n","                validation_split=validation_split)\n","                "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5KnxZVOF58Ll"},"source":[""]},{"cell_type":"code","metadata":{"id":"iE6iyrT1X_c8"},"source":["model.save(\"/models/HSI/EnsRL2DG10I10.h5\")"],"execution_count":null,"outputs":[]}]}